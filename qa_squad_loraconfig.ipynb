{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T16:24:07.682047Z","iopub.status.busy":"2024-05-13T16:24:07.681410Z","iopub.status.idle":"2024-05-13T16:24:24.012301Z","shell.execute_reply":"2024-05-13T16:24:24.011403Z","shell.execute_reply.started":"2024-05-13T16:24:07.682018Z"},"trusted":true},"outputs":[],"source":["import torch\n","import transformers\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","from peft import LoraConfig, get_peft_model\n","from datasets import load_dataset, load_from_disk"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T16:26:05.011584Z","iopub.status.busy":"2024-05-13T16:26:05.011219Z","iopub.status.idle":"2024-05-13T16:26:05.043202Z","shell.execute_reply":"2024-05-13T16:26:05.042119Z","shell.execute_reply.started":"2024-05-13T16:26:05.011541Z"},"trusted":true},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else \"cpu\""]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T16:26:11.276403Z","iopub.status.busy":"2024-05-13T16:26:11.275572Z","iopub.status.idle":"2024-05-13T16:26:11.281959Z","shell.execute_reply":"2024-05-13T16:26:11.280919Z","shell.execute_reply.started":"2024-05-13T16:26:11.276370Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'cuda'"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["device"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T16:26:18.715279Z","iopub.status.busy":"2024-05-13T16:26:18.714631Z","iopub.status.idle":"2024-05-13T16:26:22.361710Z","shell.execute_reply":"2024-05-13T16:26:22.360788Z","shell.execute_reply.started":"2024-05-13T16:26:18.715248Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"07434b62633345d49b4d5c30b1377d04","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d925ff4245a14f3cb77556e659d09f13","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"77166d876c084935a41ee7b8efa779ab","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["model = AutoModelForCausalLM.from_pretrained(\"gpt2\", device_map='auto',)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T16:26:32.589676Z","iopub.status.busy":"2024-05-13T16:26:32.589010Z","iopub.status.idle":"2024-05-13T16:26:33.582758Z","shell.execute_reply":"2024-05-13T16:26:33.581538Z","shell.execute_reply.started":"2024-05-13T16:26:32.589642Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"12d6e819fb384f73915ec6b7e61e9e71","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5285dddfcede4b598bb879545dcf352d","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ee30c9cef2674c3084f420b5acba75f7","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0f678c84c01243a2bb8296857964221f","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n","tokenizer.pad_token = tokenizer.eos_token"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T16:27:13.058746Z","iopub.status.busy":"2024-05-13T16:27:13.058281Z","iopub.status.idle":"2024-05-13T16:27:13.064304Z","shell.execute_reply":"2024-05-13T16:27:13.063368Z","shell.execute_reply.started":"2024-05-13T16:27:13.058714Z"},"trusted":true},"outputs":[],"source":["# Freeze weights\n","for param in model.parameters():\n","    param.requires_grad = False"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T16:27:18.254300Z","iopub.status.busy":"2024-05-13T16:27:18.253620Z","iopub.status.idle":"2024-05-13T16:27:18.258657Z","shell.execute_reply":"2024-05-13T16:27:18.257676Z","shell.execute_reply.started":"2024-05-13T16:27:18.254270Z"},"trusted":true},"outputs":[],"source":["# LoRA\n","config = LoraConfig(\n","    r=16,\n","    lora_alpha=32,\n","    lora_dropout=0.05,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\"\n",")"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T16:27:22.457685Z","iopub.status.busy":"2024-05-13T16:27:22.456718Z","iopub.status.idle":"2024-05-13T16:27:22.499563Z","shell.execute_reply":"2024-05-13T16:27:22.498641Z","shell.execute_reply.started":"2024-05-13T16:27:22.457648Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/peft/tuners/lora/layer.py:1059: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n","  warnings.warn(\n"]}],"source":["model = get_peft_model(model, config)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T16:28:18.896710Z","iopub.status.busy":"2024-05-13T16:28:18.895873Z","iopub.status.idle":"2024-05-13T16:28:18.928067Z","shell.execute_reply":"2024-05-13T16:28:18.927107Z","shell.execute_reply.started":"2024-05-13T16:28:18.896679Z"},"trusted":true},"outputs":[],"source":["# Load and structure data\n","data = load_from_disk(\"/kaggle/working/squad_v2\")"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T16:28:21.396189Z","iopub.status.busy":"2024-05-13T16:28:21.395359Z","iopub.status.idle":"2024-05-13T16:28:21.402110Z","shell.execute_reply":"2024-05-13T16:28:21.401103Z","shell.execute_reply.started":"2024-05-13T16:28:21.396159Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['id', 'title', 'context', 'question', 'answers'],\n","    num_rows: 130319\n","})"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["data[\"train\"]"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T16:28:23.410066Z","iopub.status.busy":"2024-05-13T16:28:23.409326Z","iopub.status.idle":"2024-05-13T16:28:23.415326Z","shell.execute_reply":"2024-05-13T16:28:23.414299Z","shell.execute_reply.started":"2024-05-13T16:28:23.410034Z"},"trusted":true},"outputs":[],"source":["def create_prompt(context, question, answer):\n","\n","    if len(answer[\"text\"]) < 1:\n","        answer = \"(ಠ_ಠ) ?\"\n","    else:\n","        answer = answer[\"text\"][0]\n","\n","    prompt = f\"### CONTEXT\\n{context}\\n\\n### QUESTION\\n{question}\\n\\n### ANSWER\\n{answer}</s>\"\n","    return prompt"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T16:28:25.880063Z","iopub.status.busy":"2024-05-13T16:28:25.879355Z","iopub.status.idle":"2024-05-13T16:30:44.093233Z","shell.execute_reply":"2024-05-13T16:30:44.092208Z","shell.execute_reply.started":"2024-05-13T16:28:25.880033Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ef9db08083b342d1a6ff7255d13a6d56","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/130319 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (25744 > 1024). Running this sequence through the model will result in indexing errors\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d2c0ed3436d4455191ffe78d76cc2bc5","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/11873 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["mapped_data = data.map(lambda samples: tokenizer(create_prompt(samples['context'], samples['question'], samples['answers'])))"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T16:30:46.709188Z","iopub.status.busy":"2024-05-13T16:30:46.708805Z","iopub.status.idle":"2024-05-13T16:30:46.715456Z","shell.execute_reply":"2024-05-13T16:30:46.714479Z","shell.execute_reply.started":"2024-05-13T16:30:46.709156Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'title', 'context', 'question', 'answers'],\n","        num_rows: 130319\n","    })\n","    validation: Dataset({\n","        features: ['id', 'title', 'context', 'question', 'answers'],\n","        num_rows: 11873\n","    })\n","})"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["data"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T16:30:48.549293Z","iopub.status.busy":"2024-05-13T16:30:48.548582Z","iopub.status.idle":"2024-05-13T16:30:48.555088Z","shell.execute_reply":"2024-05-13T16:30:48.554095Z","shell.execute_reply.started":"2024-05-13T16:30:48.549256Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'title', 'context', 'question', 'answers', 'input_ids', 'attention_mask'],\n","        num_rows: 130319\n","    })\n","    validation: Dataset({\n","        features: ['id', 'title', 'context', 'question', 'answers', 'input_ids', 'attention_mask'],\n","        num_rows: 11873\n","    })\n","})"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["mapped_data"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T16:30:56.121275Z","iopub.status.busy":"2024-05-13T16:30:56.120882Z","iopub.status.idle":"2024-05-13T16:30:56.127355Z","shell.execute_reply":"2024-05-13T16:30:56.126208Z","shell.execute_reply.started":"2024-05-13T16:30:56.121244Z"},"trusted":true},"outputs":[],"source":["def print_trainable_parameters(model):\n","    \"\"\"\n","    Prints the number of trainable parameters in the model.\n","    \"\"\"\n","    trainable_params = 0\n","    all_param = 0\n","    for _, param in model.named_parameters():\n","        all_param += param.numel()\n","        if param.requires_grad:\n","            trainable_params += param.numel()\n","    print(\n","        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n","    )"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T16:30:58.603343Z","iopub.status.busy":"2024-05-13T16:30:58.602650Z","iopub.status.idle":"2024-05-13T16:30:58.609504Z","shell.execute_reply":"2024-05-13T16:30:58.608504Z","shell.execute_reply.started":"2024-05-13T16:30:58.603310Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["trainable params: 589824 || all params: 125029632 || trainable%: 0.4717473694555863\n"]}],"source":["print_trainable_parameters(model)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T16:31:06.131486Z","iopub.status.busy":"2024-05-13T16:31:06.131098Z","iopub.status.idle":"2024-05-13T16:31:16.906333Z","shell.execute_reply":"2024-05-13T16:31:16.905405Z","shell.execute_reply.started":"2024-05-13T16:31:06.131453Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-05-13 16:31:08.305260: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-13 16:31:08.305355: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-13 16:31:08.415172: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n"]}],"source":["# TRAINING\n","trainer = transformers.Trainer(\n","    model=model,\n","    train_dataset=mapped_data[\"train\"],\n","    args=transformers.TrainingArguments(\n","        per_device_train_batch_size=4,\n","        gradient_accumulation_steps=4,\n","        warmup_steps=100,\n","        max_steps=500,\n","        learning_rate=2e-4,\n","        logging_steps=1,\n","        output_dir=\"outputs\",\n","        auto_find_batch_size=True\n","    ),\n","    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",")\n","model.config.use_cache = False"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T16:31:28.183506Z","iopub.status.busy":"2024-05-13T16:31:28.182768Z","iopub.status.idle":"2024-05-13T16:36:44.991654Z","shell.execute_reply":"2024-05-13T16:36:44.989856Z","shell.execute_reply.started":"2024-05-13T16:31:28.183471Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ·········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m API key must be 40 characters long, yours was 41\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["wandb version 0.17.0 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240513_163200-63f32suh</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/mmml_mvz/huggingface/runs/63f32suh' target=\"_blank\">celestial-wildflower-2</a></strong> to <a href='https://wandb.ai/mmml_mvz/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/mmml_mvz/huggingface' target=\"_blank\">https://wandb.ai/mmml_mvz/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/mmml_mvz/huggingface/runs/63f32suh' target=\"_blank\">https://wandb.ai/mmml_mvz/huggingface/runs/63f32suh</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='501' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [500/500 04:24, Epoch 0.06/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>3.608700</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>3.790600</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>3.866900</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>3.712600</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>3.791600</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>3.878000</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>3.918300</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>3.754800</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>3.705700</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>3.681800</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>3.764100</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>3.761300</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>3.718100</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>3.841100</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>3.932600</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>3.681700</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>3.784200</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>3.720900</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>3.612700</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>3.709000</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>3.758900</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>3.979800</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>3.822000</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>3.732100</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>3.715400</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>3.824200</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>3.787300</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>3.791800</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>3.704500</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>3.755500</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>3.769800</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>3.867500</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>3.818900</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>3.790800</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>3.728800</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>3.872000</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>3.673400</td>\n","    </tr>\n","    <tr>\n","      <td>38</td>\n","      <td>3.729800</td>\n","    </tr>\n","    <tr>\n","      <td>39</td>\n","      <td>3.744100</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>3.656200</td>\n","    </tr>\n","    <tr>\n","      <td>41</td>\n","      <td>3.736900</td>\n","    </tr>\n","    <tr>\n","      <td>42</td>\n","      <td>3.620500</td>\n","    </tr>\n","    <tr>\n","      <td>43</td>\n","      <td>3.565800</td>\n","    </tr>\n","    <tr>\n","      <td>44</td>\n","      <td>3.534100</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>3.576200</td>\n","    </tr>\n","    <tr>\n","      <td>46</td>\n","      <td>3.646000</td>\n","    </tr>\n","    <tr>\n","      <td>47</td>\n","      <td>3.630600</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>3.647000</td>\n","    </tr>\n","    <tr>\n","      <td>49</td>\n","      <td>3.506200</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>3.711000</td>\n","    </tr>\n","    <tr>\n","      <td>51</td>\n","      <td>3.613700</td>\n","    </tr>\n","    <tr>\n","      <td>52</td>\n","      <td>3.626400</td>\n","    </tr>\n","    <tr>\n","      <td>53</td>\n","      <td>3.575900</td>\n","    </tr>\n","    <tr>\n","      <td>54</td>\n","      <td>3.626100</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>3.548000</td>\n","    </tr>\n","    <tr>\n","      <td>56</td>\n","      <td>3.572800</td>\n","    </tr>\n","    <tr>\n","      <td>57</td>\n","      <td>3.650700</td>\n","    </tr>\n","    <tr>\n","      <td>58</td>\n","      <td>3.607600</td>\n","    </tr>\n","    <tr>\n","      <td>59</td>\n","      <td>3.633000</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>3.473400</td>\n","    </tr>\n","    <tr>\n","      <td>61</td>\n","      <td>3.546300</td>\n","    </tr>\n","    <tr>\n","      <td>62</td>\n","      <td>3.280200</td>\n","    </tr>\n","    <tr>\n","      <td>63</td>\n","      <td>3.456200</td>\n","    </tr>\n","    <tr>\n","      <td>64</td>\n","      <td>3.609900</td>\n","    </tr>\n","    <tr>\n","      <td>65</td>\n","      <td>3.489200</td>\n","    </tr>\n","    <tr>\n","      <td>66</td>\n","      <td>3.574400</td>\n","    </tr>\n","    <tr>\n","      <td>67</td>\n","      <td>3.439700</td>\n","    </tr>\n","    <tr>\n","      <td>68</td>\n","      <td>3.478200</td>\n","    </tr>\n","    <tr>\n","      <td>69</td>\n","      <td>3.440700</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>3.364300</td>\n","    </tr>\n","    <tr>\n","      <td>71</td>\n","      <td>3.465100</td>\n","    </tr>\n","    <tr>\n","      <td>72</td>\n","      <td>3.407900</td>\n","    </tr>\n","    <tr>\n","      <td>73</td>\n","      <td>3.405700</td>\n","    </tr>\n","    <tr>\n","      <td>74</td>\n","      <td>3.468600</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>3.241800</td>\n","    </tr>\n","    <tr>\n","      <td>76</td>\n","      <td>3.329800</td>\n","    </tr>\n","    <tr>\n","      <td>77</td>\n","      <td>3.382900</td>\n","    </tr>\n","    <tr>\n","      <td>78</td>\n","      <td>3.248100</td>\n","    </tr>\n","    <tr>\n","      <td>79</td>\n","      <td>3.494600</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>3.412200</td>\n","    </tr>\n","    <tr>\n","      <td>81</td>\n","      <td>3.362300</td>\n","    </tr>\n","    <tr>\n","      <td>82</td>\n","      <td>3.229700</td>\n","    </tr>\n","    <tr>\n","      <td>83</td>\n","      <td>3.376500</td>\n","    </tr>\n","    <tr>\n","      <td>84</td>\n","      <td>3.504300</td>\n","    </tr>\n","    <tr>\n","      <td>85</td>\n","      <td>3.400200</td>\n","    </tr>\n","    <tr>\n","      <td>86</td>\n","      <td>3.313100</td>\n","    </tr>\n","    <tr>\n","      <td>87</td>\n","      <td>3.228600</td>\n","    </tr>\n","    <tr>\n","      <td>88</td>\n","      <td>3.228000</td>\n","    </tr>\n","    <tr>\n","      <td>89</td>\n","      <td>3.267600</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>3.221500</td>\n","    </tr>\n","    <tr>\n","      <td>91</td>\n","      <td>3.253700</td>\n","    </tr>\n","    <tr>\n","      <td>92</td>\n","      <td>3.282400</td>\n","    </tr>\n","    <tr>\n","      <td>93</td>\n","      <td>3.165600</td>\n","    </tr>\n","    <tr>\n","      <td>94</td>\n","      <td>3.299500</td>\n","    </tr>\n","    <tr>\n","      <td>95</td>\n","      <td>3.251900</td>\n","    </tr>\n","    <tr>\n","      <td>96</td>\n","      <td>3.280400</td>\n","    </tr>\n","    <tr>\n","      <td>97</td>\n","      <td>3.128000</td>\n","    </tr>\n","    <tr>\n","      <td>98</td>\n","      <td>3.102900</td>\n","    </tr>\n","    <tr>\n","      <td>99</td>\n","      <td>3.203300</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>3.119700</td>\n","    </tr>\n","    <tr>\n","      <td>101</td>\n","      <td>3.207100</td>\n","    </tr>\n","    <tr>\n","      <td>102</td>\n","      <td>3.042700</td>\n","    </tr>\n","    <tr>\n","      <td>103</td>\n","      <td>3.012900</td>\n","    </tr>\n","    <tr>\n","      <td>104</td>\n","      <td>3.108400</td>\n","    </tr>\n","    <tr>\n","      <td>105</td>\n","      <td>3.163100</td>\n","    </tr>\n","    <tr>\n","      <td>106</td>\n","      <td>3.038300</td>\n","    </tr>\n","    <tr>\n","      <td>107</td>\n","      <td>3.177600</td>\n","    </tr>\n","    <tr>\n","      <td>108</td>\n","      <td>2.974200</td>\n","    </tr>\n","    <tr>\n","      <td>109</td>\n","      <td>3.139100</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>2.929100</td>\n","    </tr>\n","    <tr>\n","      <td>111</td>\n","      <td>3.095200</td>\n","    </tr>\n","    <tr>\n","      <td>112</td>\n","      <td>3.103500</td>\n","    </tr>\n","    <tr>\n","      <td>113</td>\n","      <td>3.108400</td>\n","    </tr>\n","    <tr>\n","      <td>114</td>\n","      <td>3.279800</td>\n","    </tr>\n","    <tr>\n","      <td>115</td>\n","      <td>3.109600</td>\n","    </tr>\n","    <tr>\n","      <td>116</td>\n","      <td>3.068200</td>\n","    </tr>\n","    <tr>\n","      <td>117</td>\n","      <td>3.215300</td>\n","    </tr>\n","    <tr>\n","      <td>118</td>\n","      <td>3.198600</td>\n","    </tr>\n","    <tr>\n","      <td>119</td>\n","      <td>2.965000</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>3.064200</td>\n","    </tr>\n","    <tr>\n","      <td>121</td>\n","      <td>3.135700</td>\n","    </tr>\n","    <tr>\n","      <td>122</td>\n","      <td>3.115200</td>\n","    </tr>\n","    <tr>\n","      <td>123</td>\n","      <td>3.170500</td>\n","    </tr>\n","    <tr>\n","      <td>124</td>\n","      <td>3.173400</td>\n","    </tr>\n","    <tr>\n","      <td>125</td>\n","      <td>3.162700</td>\n","    </tr>\n","    <tr>\n","      <td>126</td>\n","      <td>3.116300</td>\n","    </tr>\n","    <tr>\n","      <td>127</td>\n","      <td>3.100900</td>\n","    </tr>\n","    <tr>\n","      <td>128</td>\n","      <td>2.969700</td>\n","    </tr>\n","    <tr>\n","      <td>129</td>\n","      <td>3.042100</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>3.138700</td>\n","    </tr>\n","    <tr>\n","      <td>131</td>\n","      <td>3.186500</td>\n","    </tr>\n","    <tr>\n","      <td>132</td>\n","      <td>3.105200</td>\n","    </tr>\n","    <tr>\n","      <td>133</td>\n","      <td>3.069800</td>\n","    </tr>\n","    <tr>\n","      <td>134</td>\n","      <td>3.068200</td>\n","    </tr>\n","    <tr>\n","      <td>135</td>\n","      <td>3.068400</td>\n","    </tr>\n","    <tr>\n","      <td>136</td>\n","      <td>3.164100</td>\n","    </tr>\n","    <tr>\n","      <td>137</td>\n","      <td>3.051600</td>\n","    </tr>\n","    <tr>\n","      <td>138</td>\n","      <td>2.947400</td>\n","    </tr>\n","    <tr>\n","      <td>139</td>\n","      <td>3.030400</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>3.063300</td>\n","    </tr>\n","    <tr>\n","      <td>141</td>\n","      <td>3.081400</td>\n","    </tr>\n","    <tr>\n","      <td>142</td>\n","      <td>2.905000</td>\n","    </tr>\n","    <tr>\n","      <td>143</td>\n","      <td>3.138900</td>\n","    </tr>\n","    <tr>\n","      <td>144</td>\n","      <td>3.034000</td>\n","    </tr>\n","    <tr>\n","      <td>145</td>\n","      <td>3.163900</td>\n","    </tr>\n","    <tr>\n","      <td>146</td>\n","      <td>3.051500</td>\n","    </tr>\n","    <tr>\n","      <td>147</td>\n","      <td>3.024800</td>\n","    </tr>\n","    <tr>\n","      <td>148</td>\n","      <td>3.069600</td>\n","    </tr>\n","    <tr>\n","      <td>149</td>\n","      <td>3.127200</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>3.072100</td>\n","    </tr>\n","    <tr>\n","      <td>151</td>\n","      <td>3.202000</td>\n","    </tr>\n","    <tr>\n","      <td>152</td>\n","      <td>2.967700</td>\n","    </tr>\n","    <tr>\n","      <td>153</td>\n","      <td>3.133600</td>\n","    </tr>\n","    <tr>\n","      <td>154</td>\n","      <td>3.016100</td>\n","    </tr>\n","    <tr>\n","      <td>155</td>\n","      <td>2.897600</td>\n","    </tr>\n","    <tr>\n","      <td>156</td>\n","      <td>3.095300</td>\n","    </tr>\n","    <tr>\n","      <td>157</td>\n","      <td>3.006800</td>\n","    </tr>\n","    <tr>\n","      <td>158</td>\n","      <td>3.007700</td>\n","    </tr>\n","    <tr>\n","      <td>159</td>\n","      <td>3.157700</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>2.988100</td>\n","    </tr>\n","    <tr>\n","      <td>161</td>\n","      <td>3.145200</td>\n","    </tr>\n","    <tr>\n","      <td>162</td>\n","      <td>3.029800</td>\n","    </tr>\n","    <tr>\n","      <td>163</td>\n","      <td>3.101100</td>\n","    </tr>\n","    <tr>\n","      <td>164</td>\n","      <td>2.927600</td>\n","    </tr>\n","    <tr>\n","      <td>165</td>\n","      <td>2.926200</td>\n","    </tr>\n","    <tr>\n","      <td>166</td>\n","      <td>3.050900</td>\n","    </tr>\n","    <tr>\n","      <td>167</td>\n","      <td>2.921100</td>\n","    </tr>\n","    <tr>\n","      <td>168</td>\n","      <td>3.197200</td>\n","    </tr>\n","    <tr>\n","      <td>169</td>\n","      <td>3.205400</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>3.106600</td>\n","    </tr>\n","    <tr>\n","      <td>171</td>\n","      <td>3.000800</td>\n","    </tr>\n","    <tr>\n","      <td>172</td>\n","      <td>3.060500</td>\n","    </tr>\n","    <tr>\n","      <td>173</td>\n","      <td>3.021700</td>\n","    </tr>\n","    <tr>\n","      <td>174</td>\n","      <td>3.232000</td>\n","    </tr>\n","    <tr>\n","      <td>175</td>\n","      <td>2.872800</td>\n","    </tr>\n","    <tr>\n","      <td>176</td>\n","      <td>2.928500</td>\n","    </tr>\n","    <tr>\n","      <td>177</td>\n","      <td>3.117500</td>\n","    </tr>\n","    <tr>\n","      <td>178</td>\n","      <td>3.040400</td>\n","    </tr>\n","    <tr>\n","      <td>179</td>\n","      <td>2.904600</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>2.952300</td>\n","    </tr>\n","    <tr>\n","      <td>181</td>\n","      <td>2.953600</td>\n","    </tr>\n","    <tr>\n","      <td>182</td>\n","      <td>3.019500</td>\n","    </tr>\n","    <tr>\n","      <td>183</td>\n","      <td>2.964100</td>\n","    </tr>\n","    <tr>\n","      <td>184</td>\n","      <td>2.934400</td>\n","    </tr>\n","    <tr>\n","      <td>185</td>\n","      <td>3.046200</td>\n","    </tr>\n","    <tr>\n","      <td>186</td>\n","      <td>3.119500</td>\n","    </tr>\n","    <tr>\n","      <td>187</td>\n","      <td>2.946500</td>\n","    </tr>\n","    <tr>\n","      <td>188</td>\n","      <td>3.075000</td>\n","    </tr>\n","    <tr>\n","      <td>189</td>\n","      <td>3.142500</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>3.108700</td>\n","    </tr>\n","    <tr>\n","      <td>191</td>\n","      <td>3.214500</td>\n","    </tr>\n","    <tr>\n","      <td>192</td>\n","      <td>3.100200</td>\n","    </tr>\n","    <tr>\n","      <td>193</td>\n","      <td>3.107100</td>\n","    </tr>\n","    <tr>\n","      <td>194</td>\n","      <td>3.047800</td>\n","    </tr>\n","    <tr>\n","      <td>195</td>\n","      <td>3.063000</td>\n","    </tr>\n","    <tr>\n","      <td>196</td>\n","      <td>2.976300</td>\n","    </tr>\n","    <tr>\n","      <td>197</td>\n","      <td>3.117100</td>\n","    </tr>\n","    <tr>\n","      <td>198</td>\n","      <td>2.994300</td>\n","    </tr>\n","    <tr>\n","      <td>199</td>\n","      <td>3.107200</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>3.025000</td>\n","    </tr>\n","    <tr>\n","      <td>201</td>\n","      <td>2.778400</td>\n","    </tr>\n","    <tr>\n","      <td>202</td>\n","      <td>2.924100</td>\n","    </tr>\n","    <tr>\n","      <td>203</td>\n","      <td>2.988000</td>\n","    </tr>\n","    <tr>\n","      <td>204</td>\n","      <td>3.220900</td>\n","    </tr>\n","    <tr>\n","      <td>205</td>\n","      <td>2.903100</td>\n","    </tr>\n","    <tr>\n","      <td>206</td>\n","      <td>3.202900</td>\n","    </tr>\n","    <tr>\n","      <td>207</td>\n","      <td>2.860000</td>\n","    </tr>\n","    <tr>\n","      <td>208</td>\n","      <td>3.021900</td>\n","    </tr>\n","    <tr>\n","      <td>209</td>\n","      <td>3.111600</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>3.072700</td>\n","    </tr>\n","    <tr>\n","      <td>211</td>\n","      <td>3.100100</td>\n","    </tr>\n","    <tr>\n","      <td>212</td>\n","      <td>3.033000</td>\n","    </tr>\n","    <tr>\n","      <td>213</td>\n","      <td>2.943600</td>\n","    </tr>\n","    <tr>\n","      <td>214</td>\n","      <td>3.021100</td>\n","    </tr>\n","    <tr>\n","      <td>215</td>\n","      <td>3.280900</td>\n","    </tr>\n","    <tr>\n","      <td>216</td>\n","      <td>3.052600</td>\n","    </tr>\n","    <tr>\n","      <td>217</td>\n","      <td>3.099500</td>\n","    </tr>\n","    <tr>\n","      <td>218</td>\n","      <td>2.986200</td>\n","    </tr>\n","    <tr>\n","      <td>219</td>\n","      <td>3.038000</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>3.114300</td>\n","    </tr>\n","    <tr>\n","      <td>221</td>\n","      <td>2.985900</td>\n","    </tr>\n","    <tr>\n","      <td>222</td>\n","      <td>2.985200</td>\n","    </tr>\n","    <tr>\n","      <td>223</td>\n","      <td>3.006900</td>\n","    </tr>\n","    <tr>\n","      <td>224</td>\n","      <td>2.866000</td>\n","    </tr>\n","    <tr>\n","      <td>225</td>\n","      <td>2.984200</td>\n","    </tr>\n","    <tr>\n","      <td>226</td>\n","      <td>2.990600</td>\n","    </tr>\n","    <tr>\n","      <td>227</td>\n","      <td>3.101100</td>\n","    </tr>\n","    <tr>\n","      <td>228</td>\n","      <td>3.180100</td>\n","    </tr>\n","    <tr>\n","      <td>229</td>\n","      <td>2.956900</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>3.057500</td>\n","    </tr>\n","    <tr>\n","      <td>231</td>\n","      <td>3.028000</td>\n","    </tr>\n","    <tr>\n","      <td>232</td>\n","      <td>3.015600</td>\n","    </tr>\n","    <tr>\n","      <td>233</td>\n","      <td>3.003100</td>\n","    </tr>\n","    <tr>\n","      <td>234</td>\n","      <td>2.866100</td>\n","    </tr>\n","    <tr>\n","      <td>235</td>\n","      <td>2.958000</td>\n","    </tr>\n","    <tr>\n","      <td>236</td>\n","      <td>2.912200</td>\n","    </tr>\n","    <tr>\n","      <td>237</td>\n","      <td>3.138500</td>\n","    </tr>\n","    <tr>\n","      <td>238</td>\n","      <td>3.060400</td>\n","    </tr>\n","    <tr>\n","      <td>239</td>\n","      <td>2.904300</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>2.964900</td>\n","    </tr>\n","    <tr>\n","      <td>241</td>\n","      <td>2.983100</td>\n","    </tr>\n","    <tr>\n","      <td>242</td>\n","      <td>3.040600</td>\n","    </tr>\n","    <tr>\n","      <td>243</td>\n","      <td>3.161300</td>\n","    </tr>\n","    <tr>\n","      <td>244</td>\n","      <td>2.932700</td>\n","    </tr>\n","    <tr>\n","      <td>245</td>\n","      <td>3.018200</td>\n","    </tr>\n","    <tr>\n","      <td>246</td>\n","      <td>3.134000</td>\n","    </tr>\n","    <tr>\n","      <td>247</td>\n","      <td>3.122000</td>\n","    </tr>\n","    <tr>\n","      <td>248</td>\n","      <td>3.156500</td>\n","    </tr>\n","    <tr>\n","      <td>249</td>\n","      <td>3.153600</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>3.152800</td>\n","    </tr>\n","    <tr>\n","      <td>251</td>\n","      <td>2.953200</td>\n","    </tr>\n","    <tr>\n","      <td>252</td>\n","      <td>2.970800</td>\n","    </tr>\n","    <tr>\n","      <td>253</td>\n","      <td>3.145300</td>\n","    </tr>\n","    <tr>\n","      <td>254</td>\n","      <td>3.106200</td>\n","    </tr>\n","    <tr>\n","      <td>255</td>\n","      <td>3.185900</td>\n","    </tr>\n","    <tr>\n","      <td>256</td>\n","      <td>2.972800</td>\n","    </tr>\n","    <tr>\n","      <td>257</td>\n","      <td>2.924800</td>\n","    </tr>\n","    <tr>\n","      <td>258</td>\n","      <td>3.049300</td>\n","    </tr>\n","    <tr>\n","      <td>259</td>\n","      <td>3.037000</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>3.099900</td>\n","    </tr>\n","    <tr>\n","      <td>261</td>\n","      <td>2.974300</td>\n","    </tr>\n","    <tr>\n","      <td>262</td>\n","      <td>3.143900</td>\n","    </tr>\n","    <tr>\n","      <td>263</td>\n","      <td>3.013900</td>\n","    </tr>\n","    <tr>\n","      <td>264</td>\n","      <td>3.197800</td>\n","    </tr>\n","    <tr>\n","      <td>265</td>\n","      <td>3.115900</td>\n","    </tr>\n","    <tr>\n","      <td>266</td>\n","      <td>2.955700</td>\n","    </tr>\n","    <tr>\n","      <td>267</td>\n","      <td>3.046100</td>\n","    </tr>\n","    <tr>\n","      <td>268</td>\n","      <td>3.078700</td>\n","    </tr>\n","    <tr>\n","      <td>269</td>\n","      <td>3.006300</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>2.963500</td>\n","    </tr>\n","    <tr>\n","      <td>271</td>\n","      <td>3.048200</td>\n","    </tr>\n","    <tr>\n","      <td>272</td>\n","      <td>3.137300</td>\n","    </tr>\n","    <tr>\n","      <td>273</td>\n","      <td>2.981300</td>\n","    </tr>\n","    <tr>\n","      <td>274</td>\n","      <td>3.020900</td>\n","    </tr>\n","    <tr>\n","      <td>275</td>\n","      <td>2.982900</td>\n","    </tr>\n","    <tr>\n","      <td>276</td>\n","      <td>3.026200</td>\n","    </tr>\n","    <tr>\n","      <td>277</td>\n","      <td>2.985200</td>\n","    </tr>\n","    <tr>\n","      <td>278</td>\n","      <td>3.035200</td>\n","    </tr>\n","    <tr>\n","      <td>279</td>\n","      <td>2.898600</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>3.300700</td>\n","    </tr>\n","    <tr>\n","      <td>281</td>\n","      <td>3.008100</td>\n","    </tr>\n","    <tr>\n","      <td>282</td>\n","      <td>3.103700</td>\n","    </tr>\n","    <tr>\n","      <td>283</td>\n","      <td>3.062900</td>\n","    </tr>\n","    <tr>\n","      <td>284</td>\n","      <td>2.894700</td>\n","    </tr>\n","    <tr>\n","      <td>285</td>\n","      <td>2.885900</td>\n","    </tr>\n","    <tr>\n","      <td>286</td>\n","      <td>2.849600</td>\n","    </tr>\n","    <tr>\n","      <td>287</td>\n","      <td>3.015900</td>\n","    </tr>\n","    <tr>\n","      <td>288</td>\n","      <td>3.120400</td>\n","    </tr>\n","    <tr>\n","      <td>289</td>\n","      <td>2.949100</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>2.967800</td>\n","    </tr>\n","    <tr>\n","      <td>291</td>\n","      <td>3.055400</td>\n","    </tr>\n","    <tr>\n","      <td>292</td>\n","      <td>2.872500</td>\n","    </tr>\n","    <tr>\n","      <td>293</td>\n","      <td>3.156400</td>\n","    </tr>\n","    <tr>\n","      <td>294</td>\n","      <td>2.976200</td>\n","    </tr>\n","    <tr>\n","      <td>295</td>\n","      <td>3.110500</td>\n","    </tr>\n","    <tr>\n","      <td>296</td>\n","      <td>3.115000</td>\n","    </tr>\n","    <tr>\n","      <td>297</td>\n","      <td>2.973600</td>\n","    </tr>\n","    <tr>\n","      <td>298</td>\n","      <td>2.958100</td>\n","    </tr>\n","    <tr>\n","      <td>299</td>\n","      <td>2.998400</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>3.144200</td>\n","    </tr>\n","    <tr>\n","      <td>301</td>\n","      <td>2.988700</td>\n","    </tr>\n","    <tr>\n","      <td>302</td>\n","      <td>3.079800</td>\n","    </tr>\n","    <tr>\n","      <td>303</td>\n","      <td>2.942300</td>\n","    </tr>\n","    <tr>\n","      <td>304</td>\n","      <td>2.994600</td>\n","    </tr>\n","    <tr>\n","      <td>305</td>\n","      <td>2.973500</td>\n","    </tr>\n","    <tr>\n","      <td>306</td>\n","      <td>2.990700</td>\n","    </tr>\n","    <tr>\n","      <td>307</td>\n","      <td>3.045000</td>\n","    </tr>\n","    <tr>\n","      <td>308</td>\n","      <td>3.073300</td>\n","    </tr>\n","    <tr>\n","      <td>309</td>\n","      <td>3.078600</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>3.174000</td>\n","    </tr>\n","    <tr>\n","      <td>311</td>\n","      <td>3.170100</td>\n","    </tr>\n","    <tr>\n","      <td>312</td>\n","      <td>3.033000</td>\n","    </tr>\n","    <tr>\n","      <td>313</td>\n","      <td>3.046700</td>\n","    </tr>\n","    <tr>\n","      <td>314</td>\n","      <td>3.008700</td>\n","    </tr>\n","    <tr>\n","      <td>315</td>\n","      <td>3.028900</td>\n","    </tr>\n","    <tr>\n","      <td>316</td>\n","      <td>2.914300</td>\n","    </tr>\n","    <tr>\n","      <td>317</td>\n","      <td>2.958500</td>\n","    </tr>\n","    <tr>\n","      <td>318</td>\n","      <td>2.811700</td>\n","    </tr>\n","    <tr>\n","      <td>319</td>\n","      <td>2.884600</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>2.895100</td>\n","    </tr>\n","    <tr>\n","      <td>321</td>\n","      <td>2.983000</td>\n","    </tr>\n","    <tr>\n","      <td>322</td>\n","      <td>2.992300</td>\n","    </tr>\n","    <tr>\n","      <td>323</td>\n","      <td>3.003800</td>\n","    </tr>\n","    <tr>\n","      <td>324</td>\n","      <td>3.148400</td>\n","    </tr>\n","    <tr>\n","      <td>325</td>\n","      <td>3.036800</td>\n","    </tr>\n","    <tr>\n","      <td>326</td>\n","      <td>3.025100</td>\n","    </tr>\n","    <tr>\n","      <td>327</td>\n","      <td>3.204400</td>\n","    </tr>\n","    <tr>\n","      <td>328</td>\n","      <td>2.993500</td>\n","    </tr>\n","    <tr>\n","      <td>329</td>\n","      <td>3.068300</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>3.103500</td>\n","    </tr>\n","    <tr>\n","      <td>331</td>\n","      <td>3.078300</td>\n","    </tr>\n","    <tr>\n","      <td>332</td>\n","      <td>3.071700</td>\n","    </tr>\n","    <tr>\n","      <td>333</td>\n","      <td>3.124400</td>\n","    </tr>\n","    <tr>\n","      <td>334</td>\n","      <td>3.049500</td>\n","    </tr>\n","    <tr>\n","      <td>335</td>\n","      <td>3.012700</td>\n","    </tr>\n","    <tr>\n","      <td>336</td>\n","      <td>3.020100</td>\n","    </tr>\n","    <tr>\n","      <td>337</td>\n","      <td>3.006300</td>\n","    </tr>\n","    <tr>\n","      <td>338</td>\n","      <td>2.943800</td>\n","    </tr>\n","    <tr>\n","      <td>339</td>\n","      <td>2.960600</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>3.090700</td>\n","    </tr>\n","    <tr>\n","      <td>341</td>\n","      <td>3.148900</td>\n","    </tr>\n","    <tr>\n","      <td>342</td>\n","      <td>2.893100</td>\n","    </tr>\n","    <tr>\n","      <td>343</td>\n","      <td>2.895300</td>\n","    </tr>\n","    <tr>\n","      <td>344</td>\n","      <td>3.084800</td>\n","    </tr>\n","    <tr>\n","      <td>345</td>\n","      <td>3.047800</td>\n","    </tr>\n","    <tr>\n","      <td>346</td>\n","      <td>2.918200</td>\n","    </tr>\n","    <tr>\n","      <td>347</td>\n","      <td>3.097800</td>\n","    </tr>\n","    <tr>\n","      <td>348</td>\n","      <td>3.038000</td>\n","    </tr>\n","    <tr>\n","      <td>349</td>\n","      <td>2.937600</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>3.002300</td>\n","    </tr>\n","    <tr>\n","      <td>351</td>\n","      <td>3.030500</td>\n","    </tr>\n","    <tr>\n","      <td>352</td>\n","      <td>2.949200</td>\n","    </tr>\n","    <tr>\n","      <td>353</td>\n","      <td>2.977700</td>\n","    </tr>\n","    <tr>\n","      <td>354</td>\n","      <td>2.913800</td>\n","    </tr>\n","    <tr>\n","      <td>355</td>\n","      <td>3.014100</td>\n","    </tr>\n","    <tr>\n","      <td>356</td>\n","      <td>3.058800</td>\n","    </tr>\n","    <tr>\n","      <td>357</td>\n","      <td>3.113500</td>\n","    </tr>\n","    <tr>\n","      <td>358</td>\n","      <td>2.928500</td>\n","    </tr>\n","    <tr>\n","      <td>359</td>\n","      <td>3.027300</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>2.979700</td>\n","    </tr>\n","    <tr>\n","      <td>361</td>\n","      <td>3.098900</td>\n","    </tr>\n","    <tr>\n","      <td>362</td>\n","      <td>2.814500</td>\n","    </tr>\n","    <tr>\n","      <td>363</td>\n","      <td>3.036900</td>\n","    </tr>\n","    <tr>\n","      <td>364</td>\n","      <td>3.145300</td>\n","    </tr>\n","    <tr>\n","      <td>365</td>\n","      <td>2.974400</td>\n","    </tr>\n","    <tr>\n","      <td>366</td>\n","      <td>3.172400</td>\n","    </tr>\n","    <tr>\n","      <td>367</td>\n","      <td>3.170600</td>\n","    </tr>\n","    <tr>\n","      <td>368</td>\n","      <td>2.942300</td>\n","    </tr>\n","    <tr>\n","      <td>369</td>\n","      <td>2.939900</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>3.081100</td>\n","    </tr>\n","    <tr>\n","      <td>371</td>\n","      <td>3.017500</td>\n","    </tr>\n","    <tr>\n","      <td>372</td>\n","      <td>2.909500</td>\n","    </tr>\n","    <tr>\n","      <td>373</td>\n","      <td>2.925200</td>\n","    </tr>\n","    <tr>\n","      <td>374</td>\n","      <td>3.091700</td>\n","    </tr>\n","    <tr>\n","      <td>375</td>\n","      <td>3.226600</td>\n","    </tr>\n","    <tr>\n","      <td>376</td>\n","      <td>3.144300</td>\n","    </tr>\n","    <tr>\n","      <td>377</td>\n","      <td>3.025100</td>\n","    </tr>\n","    <tr>\n","      <td>378</td>\n","      <td>3.091000</td>\n","    </tr>\n","    <tr>\n","      <td>379</td>\n","      <td>2.906300</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>3.036200</td>\n","    </tr>\n","    <tr>\n","      <td>381</td>\n","      <td>3.106000</td>\n","    </tr>\n","    <tr>\n","      <td>382</td>\n","      <td>3.105000</td>\n","    </tr>\n","    <tr>\n","      <td>383</td>\n","      <td>2.977000</td>\n","    </tr>\n","    <tr>\n","      <td>384</td>\n","      <td>3.052600</td>\n","    </tr>\n","    <tr>\n","      <td>385</td>\n","      <td>3.063800</td>\n","    </tr>\n","    <tr>\n","      <td>386</td>\n","      <td>2.918800</td>\n","    </tr>\n","    <tr>\n","      <td>387</td>\n","      <td>3.177900</td>\n","    </tr>\n","    <tr>\n","      <td>388</td>\n","      <td>3.013200</td>\n","    </tr>\n","    <tr>\n","      <td>389</td>\n","      <td>2.901600</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>3.005200</td>\n","    </tr>\n","    <tr>\n","      <td>391</td>\n","      <td>3.022800</td>\n","    </tr>\n","    <tr>\n","      <td>392</td>\n","      <td>3.085700</td>\n","    </tr>\n","    <tr>\n","      <td>393</td>\n","      <td>3.157900</td>\n","    </tr>\n","    <tr>\n","      <td>394</td>\n","      <td>3.024100</td>\n","    </tr>\n","    <tr>\n","      <td>395</td>\n","      <td>2.962700</td>\n","    </tr>\n","    <tr>\n","      <td>396</td>\n","      <td>3.169000</td>\n","    </tr>\n","    <tr>\n","      <td>397</td>\n","      <td>2.898100</td>\n","    </tr>\n","    <tr>\n","      <td>398</td>\n","      <td>2.914100</td>\n","    </tr>\n","    <tr>\n","      <td>399</td>\n","      <td>2.906900</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>3.128600</td>\n","    </tr>\n","    <tr>\n","      <td>401</td>\n","      <td>3.239700</td>\n","    </tr>\n","    <tr>\n","      <td>402</td>\n","      <td>3.102200</td>\n","    </tr>\n","    <tr>\n","      <td>403</td>\n","      <td>3.041100</td>\n","    </tr>\n","    <tr>\n","      <td>404</td>\n","      <td>2.869600</td>\n","    </tr>\n","    <tr>\n","      <td>405</td>\n","      <td>2.980900</td>\n","    </tr>\n","    <tr>\n","      <td>406</td>\n","      <td>3.009800</td>\n","    </tr>\n","    <tr>\n","      <td>407</td>\n","      <td>3.084300</td>\n","    </tr>\n","    <tr>\n","      <td>408</td>\n","      <td>2.975300</td>\n","    </tr>\n","    <tr>\n","      <td>409</td>\n","      <td>3.019500</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>2.908300</td>\n","    </tr>\n","    <tr>\n","      <td>411</td>\n","      <td>3.108800</td>\n","    </tr>\n","    <tr>\n","      <td>412</td>\n","      <td>2.917900</td>\n","    </tr>\n","    <tr>\n","      <td>413</td>\n","      <td>3.064500</td>\n","    </tr>\n","    <tr>\n","      <td>414</td>\n","      <td>2.955100</td>\n","    </tr>\n","    <tr>\n","      <td>415</td>\n","      <td>2.938900</td>\n","    </tr>\n","    <tr>\n","      <td>416</td>\n","      <td>2.981900</td>\n","    </tr>\n","    <tr>\n","      <td>417</td>\n","      <td>3.024800</td>\n","    </tr>\n","    <tr>\n","      <td>418</td>\n","      <td>3.057600</td>\n","    </tr>\n","    <tr>\n","      <td>419</td>\n","      <td>3.010800</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>3.143800</td>\n","    </tr>\n","    <tr>\n","      <td>421</td>\n","      <td>2.916400</td>\n","    </tr>\n","    <tr>\n","      <td>422</td>\n","      <td>3.172500</td>\n","    </tr>\n","    <tr>\n","      <td>423</td>\n","      <td>2.961700</td>\n","    </tr>\n","    <tr>\n","      <td>424</td>\n","      <td>2.934900</td>\n","    </tr>\n","    <tr>\n","      <td>425</td>\n","      <td>2.796300</td>\n","    </tr>\n","    <tr>\n","      <td>426</td>\n","      <td>3.140400</td>\n","    </tr>\n","    <tr>\n","      <td>427</td>\n","      <td>2.982600</td>\n","    </tr>\n","    <tr>\n","      <td>428</td>\n","      <td>3.136100</td>\n","    </tr>\n","    <tr>\n","      <td>429</td>\n","      <td>3.043400</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>3.187300</td>\n","    </tr>\n","    <tr>\n","      <td>431</td>\n","      <td>2.905500</td>\n","    </tr>\n","    <tr>\n","      <td>432</td>\n","      <td>2.866100</td>\n","    </tr>\n","    <tr>\n","      <td>433</td>\n","      <td>2.940500</td>\n","    </tr>\n","    <tr>\n","      <td>434</td>\n","      <td>3.123400</td>\n","    </tr>\n","    <tr>\n","      <td>435</td>\n","      <td>2.925300</td>\n","    </tr>\n","    <tr>\n","      <td>436</td>\n","      <td>2.977700</td>\n","    </tr>\n","    <tr>\n","      <td>437</td>\n","      <td>2.943600</td>\n","    </tr>\n","    <tr>\n","      <td>438</td>\n","      <td>2.963400</td>\n","    </tr>\n","    <tr>\n","      <td>439</td>\n","      <td>2.997700</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>2.980500</td>\n","    </tr>\n","    <tr>\n","      <td>441</td>\n","      <td>3.121900</td>\n","    </tr>\n","    <tr>\n","      <td>442</td>\n","      <td>3.081200</td>\n","    </tr>\n","    <tr>\n","      <td>443</td>\n","      <td>2.952300</td>\n","    </tr>\n","    <tr>\n","      <td>444</td>\n","      <td>2.940400</td>\n","    </tr>\n","    <tr>\n","      <td>445</td>\n","      <td>3.126700</td>\n","    </tr>\n","    <tr>\n","      <td>446</td>\n","      <td>2.919900</td>\n","    </tr>\n","    <tr>\n","      <td>447</td>\n","      <td>3.137700</td>\n","    </tr>\n","    <tr>\n","      <td>448</td>\n","      <td>2.846700</td>\n","    </tr>\n","    <tr>\n","      <td>449</td>\n","      <td>3.089200</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>3.123800</td>\n","    </tr>\n","    <tr>\n","      <td>451</td>\n","      <td>2.949600</td>\n","    </tr>\n","    <tr>\n","      <td>452</td>\n","      <td>2.970400</td>\n","    </tr>\n","    <tr>\n","      <td>453</td>\n","      <td>3.004100</td>\n","    </tr>\n","    <tr>\n","      <td>454</td>\n","      <td>3.256300</td>\n","    </tr>\n","    <tr>\n","      <td>455</td>\n","      <td>3.048900</td>\n","    </tr>\n","    <tr>\n","      <td>456</td>\n","      <td>2.857600</td>\n","    </tr>\n","    <tr>\n","      <td>457</td>\n","      <td>3.028100</td>\n","    </tr>\n","    <tr>\n","      <td>458</td>\n","      <td>3.119400</td>\n","    </tr>\n","    <tr>\n","      <td>459</td>\n","      <td>3.124100</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>3.153100</td>\n","    </tr>\n","    <tr>\n","      <td>461</td>\n","      <td>3.010300</td>\n","    </tr>\n","    <tr>\n","      <td>462</td>\n","      <td>2.899400</td>\n","    </tr>\n","    <tr>\n","      <td>463</td>\n","      <td>3.156700</td>\n","    </tr>\n","    <tr>\n","      <td>464</td>\n","      <td>3.101300</td>\n","    </tr>\n","    <tr>\n","      <td>465</td>\n","      <td>2.951700</td>\n","    </tr>\n","    <tr>\n","      <td>466</td>\n","      <td>2.943100</td>\n","    </tr>\n","    <tr>\n","      <td>467</td>\n","      <td>3.171800</td>\n","    </tr>\n","    <tr>\n","      <td>468</td>\n","      <td>2.995200</td>\n","    </tr>\n","    <tr>\n","      <td>469</td>\n","      <td>2.821900</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>2.921500</td>\n","    </tr>\n","    <tr>\n","      <td>471</td>\n","      <td>3.032400</td>\n","    </tr>\n","    <tr>\n","      <td>472</td>\n","      <td>3.079100</td>\n","    </tr>\n","    <tr>\n","      <td>473</td>\n","      <td>2.939600</td>\n","    </tr>\n","    <tr>\n","      <td>474</td>\n","      <td>3.009600</td>\n","    </tr>\n","    <tr>\n","      <td>475</td>\n","      <td>3.019700</td>\n","    </tr>\n","    <tr>\n","      <td>476</td>\n","      <td>2.973800</td>\n","    </tr>\n","    <tr>\n","      <td>477</td>\n","      <td>2.986800</td>\n","    </tr>\n","    <tr>\n","      <td>478</td>\n","      <td>3.082700</td>\n","    </tr>\n","    <tr>\n","      <td>479</td>\n","      <td>3.030000</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>3.017500</td>\n","    </tr>\n","    <tr>\n","      <td>481</td>\n","      <td>2.868800</td>\n","    </tr>\n","    <tr>\n","      <td>482</td>\n","      <td>3.065400</td>\n","    </tr>\n","    <tr>\n","      <td>483</td>\n","      <td>2.991300</td>\n","    </tr>\n","    <tr>\n","      <td>484</td>\n","      <td>3.089300</td>\n","    </tr>\n","    <tr>\n","      <td>485</td>\n","      <td>2.992900</td>\n","    </tr>\n","    <tr>\n","      <td>486</td>\n","      <td>3.060000</td>\n","    </tr>\n","    <tr>\n","      <td>487</td>\n","      <td>3.073800</td>\n","    </tr>\n","    <tr>\n","      <td>488</td>\n","      <td>3.202700</td>\n","    </tr>\n","    <tr>\n","      <td>489</td>\n","      <td>2.971600</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>3.083300</td>\n","    </tr>\n","    <tr>\n","      <td>491</td>\n","      <td>3.022900</td>\n","    </tr>\n","    <tr>\n","      <td>492</td>\n","      <td>2.994600</td>\n","    </tr>\n","    <tr>\n","      <td>493</td>\n","      <td>3.131600</td>\n","    </tr>\n","    <tr>\n","      <td>494</td>\n","      <td>2.826000</td>\n","    </tr>\n","    <tr>\n","      <td>495</td>\n","      <td>3.034700</td>\n","    </tr>\n","    <tr>\n","      <td>496</td>\n","      <td>3.136600</td>\n","    </tr>\n","    <tr>\n","      <td>497</td>\n","      <td>3.131000</td>\n","    </tr>\n","    <tr>\n","      <td>498</td>\n","      <td>2.972400</td>\n","    </tr>\n","    <tr>\n","      <td>499</td>\n","      <td>2.929500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"ename":"RuntimeError","evalue":"\n            Some tensors share memory, this will lead to duplicate memory on disk and potential differences when loading them again: [{'base_model.model.lm_head.weight', 'base_model.model.transformer.wte.weight'}].\n            A potential way to correctly save your model is to use `save_model`.\n            More information at https://huggingface.co/docs/safetensors/torch_shared_tensors\n            ","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1780\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1778\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1780\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1782\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1783\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/utils/memory.py:142\u001b[0m, in \u001b[0;36mfind_executable_batch_size.<locals>.decorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo executable batch size found, reached zero.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_reduce_batch_size(e):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2193\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2190\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   2191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2193\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2194\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2195\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2588\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2585\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mstep(metrics[metric_to_check])\n\u001b[1;32m   2587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 2588\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2589\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_save(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2656\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   2654\u001b[0m run_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_output_dir(trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m   2655\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(run_dir, checkpoint_folder)\n\u001b[0;32m-> 2656\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_internal_call\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_only_model:\n\u001b[1;32m   2659\u001b[0m     \u001b[38;5;66;03m# Save optimizer and scheduler\u001b[39;00m\n\u001b[1;32m   2660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_optimizer_and_scheduler(output_dir)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3150\u001b[0m, in \u001b[0;36mTrainer.save_model\u001b[0;34m(self, output_dir, _internal_call)\u001b[0m\n\u001b[1;32m   3147\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped\u001b[38;5;241m.\u001b[39msave_checkpoint(output_dir)\n\u001b[1;32m   3149\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 3150\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3152\u001b[0m \u001b[38;5;66;03m# Push to the Hub when `save_model` is called by the user.\u001b[39;00m\n\u001b[1;32m   3153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpush_to_hub \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _internal_call:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3219\u001b[0m, in \u001b[0;36mTrainer._save\u001b[0;34m(self, output_dir, state_dict)\u001b[0m\n\u001b[1;32m   3217\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrainer.model is not a `PreTrainedModel`, only saving its state dict.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_safetensors:\n\u001b[0;32m-> 3219\u001b[0m     \u001b[43msafetensors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSAFE_WEIGHTS_NAME\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mformat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[1;32m   3221\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3222\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3223\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(state_dict, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, WEIGHTS_NAME))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/safetensors/torch.py:284\u001b[0m, in \u001b[0;36msave_file\u001b[0;34m(tensors, filename, metadata)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_file\u001b[39m(\n\u001b[1;32m    254\u001b[0m     tensors: Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor],\n\u001b[1;32m    255\u001b[0m     filename: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[1;32m    256\u001b[0m     metadata: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    257\u001b[0m ):\n\u001b[1;32m    258\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;124;03m    Saves a dictionary of tensors into raw bytes in safetensors format.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m     serialize_file(\u001b[43m_flatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m, filename, metadata\u001b[38;5;241m=\u001b[39mmetadata)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/safetensors/torch.py:480\u001b[0m, in \u001b[0;36m_flatten\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    477\u001b[0m         failing\u001b[38;5;241m.\u001b[39mappend(names)\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failing:\n\u001b[0;32m--> 480\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;124m        Some tensors share memory, this will lead to duplicate memory on disk and potential differences when loading them again: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfailing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;124m        A potential way to correctly save your model is to use `save_model`.\u001b[39m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;124m        More information at https://huggingface.co/docs/safetensors/torch_shared_tensors\u001b[39m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    486\u001b[0m     )\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    489\u001b[0m     k: {\n\u001b[1;32m    490\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(v\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m tensors\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    495\u001b[0m }\n","\u001b[0;31mRuntimeError\u001b[0m: \n            Some tensors share memory, this will lead to duplicate memory on disk and potential differences when loading them again: [{'base_model.model.lm_head.weight', 'base_model.model.transformer.wte.weight'}].\n            A potential way to correctly save your model is to use `save_model`.\n            More information at https://huggingface.co/docs/safetensors/torch_shared_tensors\n            "]}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T16:48:56.524044Z","iopub.status.busy":"2024-05-13T16:48:56.523636Z","iopub.status.idle":"2024-05-13T16:48:57.255678Z","shell.execute_reply":"2024-05-13T16:48:57.254508Z","shell.execute_reply.started":"2024-05-13T16:48:56.524017Z"},"trusted":true},"outputs":[],"source":["torch.save(model.state_dict(), \"lora-question-r16.pt\")"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T16:48:59.588152Z","iopub.status.busy":"2024-05-13T16:48:59.587438Z","iopub.status.idle":"2024-05-13T16:49:00.806362Z","shell.execute_reply":"2024-05-13T16:49:00.805297Z","shell.execute_reply.started":"2024-05-13T16:48:59.588114Z"},"trusted":true},"outputs":[],"source":["model_trained = AutoModelForCausalLM.from_pretrained(\"gpt2\", device_map=\"auto\")"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T16:49:02.227796Z","iopub.status.busy":"2024-05-13T16:49:02.227084Z","iopub.status.idle":"2024-05-13T16:49:02.233712Z","shell.execute_reply":"2024-05-13T16:49:02.232495Z","shell.execute_reply.started":"2024-05-13T16:49:02.227763Z"},"trusted":true},"outputs":[],"source":["config = LoraConfig(\n","    r=16,\n","    lora_alpha=32,\n","    lora_dropout=0.05,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\"\n",")"]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":63,"metadata":{},"output_type":"execute_result"}],"source":["model_trained = get_peft_model(model_trained, config)\n","model_trained = model_trained.to(device)\n","model_trained.load_state_dict(torch.load(\"lora-question-r16.pt\", map_location=device))"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T16:49:09.288732Z","iopub.status.busy":"2024-05-13T16:49:09.287880Z","iopub.status.idle":"2024-05-13T16:49:09.455030Z","shell.execute_reply":"2024-05-13T16:49:09.453793Z","shell.execute_reply.started":"2024-05-13T16:49:09.288699Z"},"trusted":true},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n","tokenizer.pad_token = tokenizer.eos_token"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T16:54:33.692348Z","iopub.status.busy":"2024-05-13T16:54:33.691566Z","iopub.status.idle":"2024-05-13T16:54:34.632852Z","shell.execute_reply":"2024-05-13T16:54:34.631056Z","shell.execute_reply.started":"2024-05-13T16:54:33.692315Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]}],"source":["context = \"I like learning math and playing computer games.\"\n","question = \"What do I like to play?\"\n","model_trained.to('cpu')\n","with torch.no_grad():\n","    batch = tokenizer(f\"### CONTEXT\\n{context}\\n\\n### QUESTION\\n{question}\\n\\n### ANSWER\\n\", return_tensors='pt')\n","#     batch = tokenizer(\"“If you pay in peanuts, you get monkeys” ->: \", return_tensors=\"pt\").to(device)\n","    output_tokens = model_trained.generate(**batch, max_new_tokens=25)"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T16:54:35.408285Z","iopub.status.busy":"2024-05-13T16:54:35.407789Z","iopub.status.idle":"2024-05-13T16:54:35.416826Z","shell.execute_reply":"2024-05-13T16:54:35.415711Z","shell.execute_reply.started":"2024-05-13T16:54:35.408245Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n"," ### CONTEXT\n","I like learning math and playing computer games.\n","\n","### QUESTION\n","What do I like to play?\n","\n","### ANSWER\n","\n","I like to play games.\n","\n","### QUESTION\n","\n","What do I like to play?\n","\n","### AN\n"]}],"source":["print(\"\\n\\n\", tokenizer.decode(output_tokens[0], skip_special_tokens=True))"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4999920,"sourceId":8402892,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":4}
